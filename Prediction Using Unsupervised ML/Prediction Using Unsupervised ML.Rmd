---
title: "Prediction using Unsupervised ML"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Importing and reading IRIS Dataset

```{r}
data <- read.csv("Iris.csv")
head(data)
```
 
#### Summary of the dataset

```{r}
summary(data)
```
##### Extracting Features from the dataset
```{r}
keeps <- c("SepalLengthCm","SepalWidthCm","PetalLengthCm","PetalWidthCm")
df = data[keeps]
head(df)
```

```{r}
library(ggplot2)
```
## Plotting graph between PetalLengthCm and  PetalWidthCm
```{r}
ggplot(data, aes(PetalLengthCm, PetalWidthCm)) + geom_point(aes(col=Species), size=4)
```

 

## Plotting graph between SepalLengthCm and  SepalLengthCm
```{r}
ggplot(data, aes(SepalLengthCm, SepalWidthCm)) + geom_point(aes(col=Species), size=4)

 

```
##### Finding the ideal number of cluster
```{r}
tot.withinss <- vector(mode="character", length=10)
for (i in 1:10){
  irisCluster <- kmeans(df[,1:4], center=i, nstart=20)
  tot.withinss[i] <- irisCluster$tot.withinss
}
plot(1:10, tot.withinss, type="b", pch=19)
```
####To know the exact number of clusters, We have used the elbow method... 

#### Plotting the clusters and visualizing them....

```{r}
library(cluster)
df <- kmeans(df[,1:4], center=3, nstart=20)

clusplot(iris, df$cluster, color=T, shade=T, labels=0, lines=0)
```